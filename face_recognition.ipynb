{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "file_name = \"data/NASA_Astronaut_Group_18.jpg\"\n",
    "\n",
    "img = cv2.imread(file_name, 0)\n",
    "grey_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "faces = haar_cascade.detectMultiScale(grey_img, scaleFactor=1.15, minNeighbors=3, minSize=(60, 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cropped_image = img[y:y+h, x: x+w]\n",
    "    target_file_name = 'stored_faces/' + str(i) + '.jpg'\n",
    "    cv2.imwrite(target_file_name, cropped_image)\n",
    "    i = i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YuNet\n",
    "https://medium.com/pythons-gurus/what-is-the-best-face-detector-ab650d8c1225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-26 14:21:10--  https://github.com/astaileyyoung/CineFace/raw/main/research/data/face_detection_yunet_2023mar.onnx\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/astaileyyoung/CineFace/main/research/data/face_detection_yunet_2023mar.onnx [following]\n",
      "--2024-07-26 14:21:10--  https://raw.githubusercontent.com/astaileyyoung/CineFace/main/research/data/face_detection_yunet_2023mar.onnx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 232589 (227K) [application/octet-stream]\n",
      "Saving to: ‘./model/face_detection_yunet_2023mar.onnx’\n",
      "\n",
      "face_detection_yune 100%[===================>] 227.14K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2024-07-26 14:21:11 (5.61 MB/s) - ‘./model/face_detection_yunet_2023mar.onnx’ saved [232589/232589]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/astaileyyoung/CineFace/raw/main/research/data/face_detection_yunet_2023mar.onnx -P ./model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:86\u001b[0;36m\u001b[0m\n\u001b[0;31m    return data\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class FaceDetectorYunet():\n",
    "    def __init__(self, model_path='./face_detection_yunet_2023mar.onnx', img_size=(300, 300), threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.img_size = img_size\n",
    "        self.fd = cv2.FaceDetectorYN_create(str(model_path), \"\", img_size, score_threshold=threshold)\n",
    "\n",
    "\n",
    "    def draw_faces(self, image, faces, draw_landmarks=False, show_confidence=False):\n",
    "        for face in faces:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            cv2.rectangle(image, (face['x1'], face['y1']), (face['x2'], face['y2']), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if draw_landmarks:\n",
    "                landmarks = face['landmarks']\n",
    "                for landmark in landmarks:\n",
    "                    radius = 5\n",
    "                    thickness = -1\n",
    "                    cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if show_confidence:\n",
    "                confidence = face['confidence']\n",
    "                confidence = \"{:.2f}\".format(confidence)\n",
    "                position = (face['x1'], face['y1'] - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                scale = 0.5\n",
    "                thickness = 2\n",
    "                cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def scale_coords(self, image, prediction):\n",
    "        ih, iw = image.shape[:2]\n",
    "        rw, rh = self.img_size\n",
    "        a = np.array([\n",
    "                (prediction['x1'], prediction['y1']),\n",
    "                (prediction['x1'] + prediction['x2'], prediction['y1'] + prediction['y2'])\n",
    "                    ])\n",
    "        b = np.array([iw/rw, ih/rh])\n",
    "        c = a * b\n",
    "        prediction['img_width'] = iw\n",
    "        prediction['img_height'] = ih\n",
    "        prediction['x1'] = int(c[0,0].round())\n",
    "        prediction['x2'] = int(c[1,0].round())\n",
    "        prediction['y1'] = int(c[0,1].round())\n",
    "        prediction['y2'] = int(c[1,1].round())\n",
    "        prediction['face_width'] = (c[1,0] - c[0,0])\n",
    "        prediction['face_height'] = (c[1,1] - c[0,1])\n",
    "        # prediction['face_width'] = prediction['x2'] - prediction['x1']\n",
    "        # prediction['face_height'] = prediction['y2'] - prediction['y1']\n",
    "        prediction['area'] = prediction['face_width'] * prediction['face_height']\n",
    "        prediction['pct_of_frame'] = prediction['area']/(prediction['img_width'] * prediction['img_height'])\n",
    "        return prediction\n",
    "\n",
    "    def detect(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(str(image))\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        self.fd.setInputSize(self.img_size)\n",
    "        _, faces = self.fd.detect(img)\n",
    "        if faces is None:\n",
    "            return None\n",
    "        else:\n",
    "            predictions = self.parse_predictions(image, faces)\n",
    "            return predictions\n",
    "\n",
    "    def parse_predictions(self, image, faces):\n",
    "        data = []\n",
    "        for num, face in enumerate(list(faces)):\n",
    "            x1, y1, x2, y2 = list(map(int, face[:4]))\n",
    "            landmarks = list(map(int, face[4:len(face)-1]))\n",
    "            landmarks = np.array_split(landmarks, len(landmarks) / 2)\n",
    "            positions = ['left_eye', 'right_eye', 'nose', 'right_mouth', 'left_mouth']\n",
    "            landmarks = {positions[num]: x.tolist() for num, x in enumerate(landmarks)}\n",
    "            confidence = face[-1]\n",
    "            datum = {'x1': x1,\n",
    "            'y1': y1,\n",
    "            'x2': x2,\n",
    "            'y2': y2,\n",
    "            'face_num': num,\n",
    "            'landmarks': landmarks,\n",
    "            'confidence': confidence,\n",
    "            'model': 'yunet'}\n",
    "        d = self.scale_coords(image, datum)\n",
    "        data.append(d)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerecog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
