{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image\n",
    "# !pip install onnxruntime insightface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "file_name = \"data/955px-NASA_Astronaut_Group_18.jpg\"\n",
    "\n",
    "img = cv2.imread(file_name, 0)\n",
    "grey_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "faces = haar_cascade.detectMultiScale(grey_img, scaleFactor=1.15, minNeighbors=3, minSize=(60, 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cropped_image = img[y:y+h, x: x+w]\n",
    "    target_file_name = 'stored_faces/' + str(i) + '.jpg'\n",
    "    cv2.imwrite(target_file_name, cropped_image)\n",
    "    i = i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reference  \n",
    "YuNet\n",
    "https://medium.com/pythons-gurus/what-is-the-best-face-detector-ab650d8c1225  \n",
    "https://learnopencv.com/what-is-face-detection-the-ultimate-guide/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/astaileyyoung/CineFace/raw/main/research/data/face_detection_yunet_2023mar.onnx -P ./model/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectorYunet():\n",
    "    def __init__(self, model_path='./face_detection_yunet_2023mar.onnx',\n",
    "                 img_size=(400, 400),\n",
    "                 threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.img_size = img_size\n",
    "        self.fd = cv2.FaceDetectorYN_create(str(model_path),\n",
    "                                            \"\",\n",
    "                                             img_size,\n",
    "                                             score_threshold=threshold)\n",
    "\n",
    "\n",
    "    def draw_faces(self,\n",
    "                   image,\n",
    "                   faces,\n",
    "                   draw_landmarks=False,\n",
    "                   show_confidence=False):\n",
    "        for face in faces:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            cv2.rectangle(image, (face['x1'], face['y1']), (face['x2'], face['y2']), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if draw_landmarks:\n",
    "                landmarks = face['landmarks']\n",
    "                for landmark in landmarks:\n",
    "                    radius = 5\n",
    "                    thickness = -1\n",
    "                    cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if show_confidence:\n",
    "                confidence = face['confidence']\n",
    "                confidence = \"{:.2f}\".format(confidence)\n",
    "                position = (face['x1'], face['y1'] - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                scale = 0.5\n",
    "                thickness = 2\n",
    "                cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def scale_coords(self, image, prediction):\n",
    "        ih, iw = image.shape[:2]\n",
    "        rw, rh = self.img_size\n",
    "        a = np.array([\n",
    "                (prediction['x1'], prediction['y1']),\n",
    "                (prediction['x1'] + prediction['x2'], prediction['y1'] + prediction['y2'])\n",
    "                    ])\n",
    "        b = np.array([iw/rw, ih/rh])\n",
    "        c = a * b\n",
    "        prediction['img_width'] = iw\n",
    "        prediction['img_height'] = ih\n",
    "        prediction['x1'] = int(c[0,0].round())\n",
    "        prediction['x2'] = int(c[1,0].round())\n",
    "        prediction['y1'] = int(c[0,1].round())\n",
    "        prediction['y2'] = int(c[1,1].round())\n",
    "        prediction['face_width'] = (c[1,0] - c[0,0])\n",
    "        prediction['face_height'] = (c[1,1] - c[0,1])\n",
    "        # prediction['face_width'] = prediction['x2'] - prediction['x1']\n",
    "        # prediction['face_height'] = prediction['y2'] - prediction['y1']\n",
    "        prediction['area'] = prediction['face_width'] * prediction['face_height']\n",
    "        prediction['pct_of_frame'] = prediction['area']/(prediction['img_width'] * prediction['img_height'])\n",
    "        return prediction\n",
    "\n",
    "    def detect(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(str(image))\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "        img = cv2.resize(gray_img, self.img_size)\n",
    "        self.fd.setInputSize(self.img_size)\n",
    "        _, faces = self.fd.detect(img)\n",
    "        if faces is None:\n",
    "            return None\n",
    "        else:\n",
    "            predictions = self.parse_predictions(image, faces)\n",
    "            return predictions\n",
    "\n",
    "    def parse_predictions(self, image, faces):\n",
    "        data = []\n",
    "        for num, face in enumerate(list(faces)):\n",
    "            x1, y1, x2, y2 = list(map(int, face[:4]))\n",
    "            landmarks = list(map(int, face[4:len(face)-1]))\n",
    "            landmarks = np.array_split(landmarks, len(landmarks) / 2)\n",
    "            positions = ['left_eye', 'right_eye', 'nose', 'right_mouth', 'left_mouth']\n",
    "            landmarks = {positions[num]: x.tolist() for num, x in enumerate(landmarks)}\n",
    "            confidence = face[-1]\n",
    "            datum = {'x1': x1,\n",
    "            'y1': y1,\n",
    "            'x2': x2,\n",
    "            'y2': y2,\n",
    "            'face_num': num,\n",
    "            'landmarks': landmarks,\n",
    "            'confidence': confidence,\n",
    "            'model': 'yunet'}\n",
    "        d = self.scale_coords(image, datum)\n",
    "        data.append(d)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectorYunet():\n",
    "    def __init__(self,\n",
    "                  model_path='./face_detection_yunet_2023mar.onnx',\n",
    "                  img_size=(300, 300),\n",
    "                  threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.img_size = img_size\n",
    "        self.fd = cv2.FaceDetectorYN_create(str(model_path),\n",
    "                                            \"\",\n",
    "                                            img_size,\n",
    "                                            score_threshold=threshold)\n",
    "\n",
    "    def draw_faces(self,\n",
    "                   image,\n",
    "                   faces,\n",
    "                   draw_landmarks=False,\n",
    "                   show_confidence=False):\n",
    "        for face in faces:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            cv2.rectangle(image, (face['x1'], face['y1']), (face['x2'], face['y2']), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if draw_landmarks:\n",
    "                landmarks = face['landmarks']\n",
    "                for landmark in landmarks:\n",
    "                    radius = 5\n",
    "                    thickness = -1\n",
    "                    cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if show_confidence:\n",
    "                confidence = face['confidence']\n",
    "                confidence = \"{:.2f}\".format(confidence)\n",
    "                position = (face['x1'], face['y1'] - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                scale = 0.5\n",
    "                thickness = 2\n",
    "                cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def scale_coords(self, image, prediction):\n",
    "        ih, iw = image.shape[:2]\n",
    "        rw, rh = self.img_size\n",
    "        a = np.array([\n",
    "                (prediction['x1'], prediction['y1']),\n",
    "                (prediction['x1'] + prediction['x2'], prediction['y1'] + prediction['y2'])\n",
    "                    ])\n",
    "        b = np.array([iw/rw, ih/rh])\n",
    "        c = a * b\n",
    "        prediction['img_width'] = iw\n",
    "        prediction['img_height'] = ih\n",
    "        prediction['x1'] = int(c[0,0].round())\n",
    "        prediction['x2'] = int(c[1,0].round())\n",
    "        prediction['y1'] = int(c[0,1].round())\n",
    "        prediction['y2'] = int(c[1,1].round())\n",
    "        prediction['face_width'] = (c[1,0] - c[0,0])\n",
    "        prediction['face_height'] = (c[1,1] - c[0,1])\n",
    "        # prediction['face_width'] = prediction['x2'] - prediction['x1']\n",
    "        # prediction['face_height'] = prediction['y2'] - prediction['y1']\n",
    "        prediction['area'] = prediction['face_width'] * prediction['face_height']\n",
    "        prediction['pct_of_frame'] = prediction['area']/(prediction['img_width'] * prediction['img_height'])\n",
    "        return prediction\n",
    "\n",
    "    def detect(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(str(image))\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        self.fd.setInputSize(self.img_size)\n",
    "        _, faces = self.fd.detect(img)\n",
    "        if faces is None:\n",
    "            return None\n",
    "        else:\n",
    "            predictions = self.parse_predictions(image, faces)\n",
    "            return predictions\n",
    "\n",
    "    def parse_predictions(self,\n",
    "                          image,\n",
    "                          faces):\n",
    "        data = []\n",
    "        for num, face in enumerate(list(faces)):\n",
    "            x1, y1, x2, y2 = list(map(int, face[:4]))\n",
    "            landmarks = list(map(int, face[4:len(face)-1]))\n",
    "            landmarks = np.array_split(landmarks, len(landmarks) / 2)\n",
    "            positions = ['left_eye', 'right_eye', 'nose', 'right_mouth', 'left_mouth']\n",
    "            landmarks = {positions[num]: x.tolist() for num, x in enumerate(landmarks)}\n",
    "            confidence = face[-1]\n",
    "            datum = {'x1': x1,\n",
    "                     'y1': y1,\n",
    "                     'x2': x2,\n",
    "                     'y2': y2,\n",
    "                     'face_num': num,\n",
    "                     'landmarks': landmarks,\n",
    "                     'confidence': confidence,\n",
    "                     'model': 'yunet'}\n",
    "            d = self.scale_coords(image, datum)\n",
    "            data.append(d)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "def show_image(image):\n",
    "    _, ret = cv2.imencode('.jpg', image)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FaceDetectorYunet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_1.jpg?raw=true')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_2.jpg?raw=true')\n",
    "img = io.imread('./data/img_2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/636px-NASA_Astronaut_Group_18.jpg\"\n",
    "file_name = \"data/img_2.jpg\"\n",
    "\n",
    "# img = cv2.imread(file_name, 0)\n",
    "img = io.imread(file_name)\n",
    "# img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_2.jpg?raw=true')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fd = FaceDetectorYunet()\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://medium.com/@yongsun.yoon/nba-face-recognition-system-345034ffed8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiap/miniconda3/envs/cv/lib/python3.11/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.18 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/home/aiap/miniconda3/envs/cv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "from insightface.app.common import Face\n",
    "from insightface.model_zoo import model_zoo\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "det_model_path = 'buffalo_s/det_500m.onnx'\n",
    "rec_model_path = 'buffalo_s/w600k_mbf.onnx'\n",
    "\n",
    "det_model = model_zoo.get_model(f'./model/{det_model_path}')\n",
    "rec_model = model_zoo.get_model(f'./model/{rec_model_path}')\n",
    "\n",
    "det_model.prepare(ctx_id=0, input_size=(640, 640), det_thres=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(218, 327, 3)\n"
     ]
    }
   ],
   "source": [
    "# file_name = [\"data/636px-NASA_Astronaut_Group_18.jpg\", \"data/955px-NASA_Astronaut_Group_18.jpg\",\"data/1432px-NASA_Astronaut_Group_18.jpg\", \"data/foreign-workers-5.jpg\"]\n",
    "# file_name = [\"data/Ss.jpg\", 'data/test.jpeg', 'data/jxjy.jpeg']\n",
    "file_name = ['data/ref_data/lwk.jpg']\n",
    "img = cv2.imread(file_name[0], cv2.IMREAD_UNCHANGED)\n",
    "bboxes, kpss = det_model.detect(img, max_num=0, metric='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(image,\n",
    "               faces,\n",
    "               draw_landmarks=False,\n",
    "               show_confidence=False,\n",
    "               names=[],\n",
    "               show_names=False):\n",
    "    \n",
    "    for i, face in enumerate(faces):\n",
    "        color = (0, 255, 255)\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (int(face[0]), int(face[1])), (int(face[2]), int(face[3])), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        if draw_landmarks:\n",
    "            landmarks = face['landmarks']\n",
    "            for landmark in landmarks:\n",
    "                radius = 5\n",
    "                thickness = -1\n",
    "                cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        if show_confidence:\n",
    "            confidence = face[4]\n",
    "            confidence = \"{:.2f}\".format(confidence)\n",
    "            position = (int(face[0]), int(face[1] - 10))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            scale = 0.5\n",
    "            thickness = 1\n",
    "            cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        if show_names and len(faces)==len(names):\n",
    "\n",
    "            position = (int(face[0]), int(face[1] - 25))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            scale = 0.5\n",
    "            thickness = 1\n",
    "            cv2.putText(image, names[i], position, font, scale, color, thickness, cv2.LINE_AA)            \n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.putText(img=img,'Test',(100,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = draw_faces(img,bboxes, show_confidence=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get first bounding box and keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = bboxes[0, :4]\n",
    "confidence_score = bboxes[0, 4]\n",
    "# keypoint\n",
    "# det_score\n",
    "\n",
    "bboxes[1,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# face = bboxes[0]\n",
    "color = (0, 0, 255)\n",
    "# thickness = 2\n",
    "# cv2.rectangle(img, (int(face[0]), int(face[1])), (int(face[2]), int(face[3])), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "cv2.circle(img=img, center=(201,116), radius=3, color=color, thickness=2)\n",
    "cv2.circle(img=img, center=(231,118), radius=2, color=(0, 255, 0), thickness=2)\n",
    "cv2.circle(img=img, center=(217, 134), radius=2, color=(0, 0, 255), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "def show_image(image):\n",
    "    _, ret = cv2.imencode('.jpg', image)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data_dir = os.path.join('data', 'ref_data')\n",
    "ref_files = [file for file in os.listdir(ref_data_dir) if os.path.isfile(os.path.join(ref_data_dir,file))]\n",
    "# print(ref_files)\n",
    "# file_name = os.path.join(ref_data_dir,ref_files[0])\n",
    "# img = cv2.imread(file_name, cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "WIDTH = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_embeddings, ref_names = [], []\n",
    "\n",
    "for file in ref_files:\n",
    "\n",
    "    file_path = os.path.join(ref_data_dir,file)\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    print(file.split('.'))\n",
    "    print(img.shape)\n",
    "    (h, w) = img.shape[:2]\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    new_height = int(WIDTH /aspect_ratio)\n",
    "\n",
    "    # print(f'{new_height}')\n",
    "    img = cv2.resize(img,(WIDTH, new_height))\n",
    "    print(f'Resize shape: {img.shape}')\n",
    "\n",
    "    bboxes, kpss = det_model.detect(img, max_num=0, metric='default')\n",
    "    # img = draw_faces(img,bboxes, show_confidence=True)\n",
    "\n",
    "    bbox = bboxes[0,:4]\n",
    "    confidence_score = bboxes[0,4]\n",
    "\n",
    "    kps = kpss[0]\n",
    "    # print(f'bbox shape: {bbox.shape}')\n",
    "    # print(f'kpss shape {kpss.shape}')\n",
    "\n",
    "    face = Face(bbox=bbox, kps = kps, det_score =confidence_score)\n",
    "    rec_model.get(img, face)\n",
    "\n",
    "    ref_embeddings.append(face.normed_embedding)\n",
    "    ref_names.append(file.split('.')[0])\n",
    "\n",
    "\n",
    "    # show_image(img)\n",
    "    # time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reference embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ref_embeddings))\n",
    "print(ref_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [\"data/Ss.jpg\", 'data/test.jpeg']\n",
    "img = cv2.imread(file_name[0], cv2.IMREAD_UNCHANGED)\n",
    "bboxes, kpss = det_model.detect(img, max_num=0, metric='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes.shape\n",
    "img = draw_faces(img,bboxes, show_confidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search (ref_embeddings, ref_names, unknown_embedding, threshold):\n",
    "    score = np.dot(ref_embeddings, unknown_embedding)\n",
    "    score = np.clip(score, 0, 1)\n",
    "    idx = np.argmax(score, axis=0)\n",
    "    id = 'unknown' # Set default id to unknown\n",
    "    if score[idx] > threshold:\n",
    "        id = ref_names[idx]\n",
    "    return id\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for bbox, kps in zip(bboxes, kpss):\n",
    "    confidence_score = bbox[4]\n",
    "    bbox = bbox[0:4]\n",
    "    face = Face(bbox=bbox, kps = kps, det_score =confidence_score)\n",
    "    rec_model.get(img, face)\n",
    "    # predict_face_embbedding = face.normed_embedding\n",
    "    id =search(ref_embeddings=ref_embeddings,\n",
    "           ref_names=ref_names,\n",
    "           unknown_embedding=face.normed_embedding,\n",
    "           threshold=0.5)\n",
    "    ids.append(id)\n",
    "\n",
    "    \n",
    "img = draw_faces(img,bboxes, show_confidence=True, names=ids, show_names= True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
