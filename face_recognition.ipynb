{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deepface\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-image\n",
    "# !pip install onnxruntime insightface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "file_name = \"data/955px-NASA_Astronaut_Group_18.jpg\"\n",
    "\n",
    "img = cv2.imread(file_name, 0)\n",
    "grey_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "faces = haar_cascade.detectMultiScale(grey_img, scaleFactor=1.15, minNeighbors=3, minSize=(60, 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cropped_image = img[y:y+h, x: x+w]\n",
    "    target_file_name = 'stored_faces/' + str(i) + '.jpg'\n",
    "    cv2.imwrite(target_file_name, cropped_image)\n",
    "    i = i+1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reference  \n",
    "YuNet\n",
    "https://medium.com/pythons-gurus/what-is-the-best-face-detector-ab650d8c1225  \n",
    "https://learnopencv.com/what-is-face-detection-the-ultimate-guide/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-07 05:13:32--  https://github.com/astaileyyoung/CineFace/raw/main/research/data/face_detection_yunet_2023mar.onnx\n",
      "Resolving github.com (github.com)... 20.205.243.166\n",
      "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/astaileyyoung/CineFace/main/research/data/face_detection_yunet_2023mar.onnx [following]\n",
      "--2024-08-07 05:13:33--  https://raw.githubusercontent.com/astaileyyoung/CineFace/main/research/data/face_detection_yunet_2023mar.onnx\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 232589 (227K) [application/octet-stream]\n",
      "Saving to: ‘./model/face_detection_yunet_2023mar.onnx.1’\n",
      "\n",
      "face_detection_yune 100%[===================>] 227.14K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-08-07 05:13:33 (1.97 MB/s) - ‘./model/face_detection_yunet_2023mar.onnx.1’ saved [232589/232589]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/astaileyyoung/CineFace/raw/main/research/data/face_detection_yunet_2023mar.onnx -P ./model/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectorYunet():\n",
    "    def __init__(self, model_path='./face_detection_yunet_2023mar.onnx',\n",
    "                 img_size=(400, 400),\n",
    "                 threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.img_size = img_size\n",
    "        self.fd = cv2.FaceDetectorYN_create(str(model_path),\n",
    "                                            \"\",\n",
    "                                             img_size,\n",
    "                                             score_threshold=threshold)\n",
    "\n",
    "\n",
    "    def draw_faces(self,\n",
    "                   image,\n",
    "                   faces,\n",
    "                   draw_landmarks=False,\n",
    "                   show_confidence=False):\n",
    "        for face in faces:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            cv2.rectangle(image, (face['x1'], face['y1']), (face['x2'], face['y2']), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if draw_landmarks:\n",
    "                landmarks = face['landmarks']\n",
    "                for landmark in landmarks:\n",
    "                    radius = 5\n",
    "                    thickness = -1\n",
    "                    cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if show_confidence:\n",
    "                confidence = face['confidence']\n",
    "                confidence = \"{:.2f}\".format(confidence)\n",
    "                position = (face['x1'], face['y1'] - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                scale = 0.5\n",
    "                thickness = 2\n",
    "                cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def scale_coords(self, image, prediction):\n",
    "        ih, iw = image.shape[:2]\n",
    "        rw, rh = self.img_size\n",
    "        a = np.array([\n",
    "                (prediction['x1'], prediction['y1']),\n",
    "                (prediction['x1'] + prediction['x2'], prediction['y1'] + prediction['y2'])\n",
    "                    ])\n",
    "        b = np.array([iw/rw, ih/rh])\n",
    "        c = a * b\n",
    "        prediction['img_width'] = iw\n",
    "        prediction['img_height'] = ih\n",
    "        prediction['x1'] = int(c[0,0].round())\n",
    "        prediction['x2'] = int(c[1,0].round())\n",
    "        prediction['y1'] = int(c[0,1].round())\n",
    "        prediction['y2'] = int(c[1,1].round())\n",
    "        prediction['face_width'] = (c[1,0] - c[0,0])\n",
    "        prediction['face_height'] = (c[1,1] - c[0,1])\n",
    "        # prediction['face_width'] = prediction['x2'] - prediction['x1']\n",
    "        # prediction['face_height'] = prediction['y2'] - prediction['y1']\n",
    "        prediction['area'] = prediction['face_width'] * prediction['face_height']\n",
    "        prediction['pct_of_frame'] = prediction['area']/(prediction['img_width'] * prediction['img_height'])\n",
    "        return prediction\n",
    "\n",
    "    def detect(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(str(image))\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "        img = cv2.resize(gray_img, self.img_size)\n",
    "        self.fd.setInputSize(self.img_size)\n",
    "        _, faces = self.fd.detect(img)\n",
    "        if faces is None:\n",
    "            return None\n",
    "        else:\n",
    "            predictions = self.parse_predictions(image, faces)\n",
    "            return predictions\n",
    "\n",
    "    def parse_predictions(self, image, faces):\n",
    "        data = []\n",
    "        for num, face in enumerate(list(faces)):\n",
    "            x1, y1, x2, y2 = list(map(int, face[:4]))\n",
    "            landmarks = list(map(int, face[4:len(face)-1]))\n",
    "            landmarks = np.array_split(landmarks, len(landmarks) / 2)\n",
    "            positions = ['left_eye', 'right_eye', 'nose', 'right_mouth', 'left_mouth']\n",
    "            landmarks = {positions[num]: x.tolist() for num, x in enumerate(landmarks)}\n",
    "            confidence = face[-1]\n",
    "            datum = {'x1': x1,\n",
    "            'y1': y1,\n",
    "            'x2': x2,\n",
    "            'y2': y2,\n",
    "            'face_num': num,\n",
    "            'landmarks': landmarks,\n",
    "            'confidence': confidence,\n",
    "            'model': 'yunet'}\n",
    "        d = self.scale_coords(image, datum)\n",
    "        data.append(d)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDetectorYunet():\n",
    "    def __init__(self,\n",
    "                  model_path='./face_detection_yunet_2023mar.onnx',\n",
    "                  img_size=(300, 300),\n",
    "                  threshold=0.5):\n",
    "        self.model_path = model_path\n",
    "        self.img_size = img_size\n",
    "        self.fd = cv2.FaceDetectorYN_create(str(model_path),\n",
    "                                            \"\",\n",
    "                                            img_size,\n",
    "                                            score_threshold=threshold)\n",
    "\n",
    "    def draw_faces(self,\n",
    "                   image,\n",
    "                   faces,\n",
    "                   draw_landmarks=False,\n",
    "                   show_confidence=False):\n",
    "        for face in faces:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            cv2.rectangle(image, (face['x1'], face['y1']), (face['x2'], face['y2']), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if draw_landmarks:\n",
    "                landmarks = face['landmarks']\n",
    "                for landmark in landmarks:\n",
    "                    radius = 5\n",
    "                    thickness = -1\n",
    "                    cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "            if show_confidence:\n",
    "                confidence = face['confidence']\n",
    "                confidence = \"{:.2f}\".format(confidence)\n",
    "                position = (face['x1'], face['y1'] - 10)\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                scale = 0.5\n",
    "                thickness = 2\n",
    "                cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "        return image\n",
    "\n",
    "    def scale_coords(self, image, prediction):\n",
    "        ih, iw = image.shape[:2]\n",
    "        rw, rh = self.img_size\n",
    "        a = np.array([\n",
    "                (prediction['x1'], prediction['y1']),\n",
    "                (prediction['x1'] + prediction['x2'], prediction['y1'] + prediction['y2'])\n",
    "                    ])\n",
    "        b = np.array([iw/rw, ih/rh])\n",
    "        c = a * b\n",
    "        prediction['img_width'] = iw\n",
    "        prediction['img_height'] = ih\n",
    "        prediction['x1'] = int(c[0,0].round())\n",
    "        prediction['x2'] = int(c[1,0].round())\n",
    "        prediction['y1'] = int(c[0,1].round())\n",
    "        prediction['y2'] = int(c[1,1].round())\n",
    "        prediction['face_width'] = (c[1,0] - c[0,0])\n",
    "        prediction['face_height'] = (c[1,1] - c[0,1])\n",
    "        # prediction['face_width'] = prediction['x2'] - prediction['x1']\n",
    "        # prediction['face_height'] = prediction['y2'] - prediction['y1']\n",
    "        prediction['area'] = prediction['face_width'] * prediction['face_height']\n",
    "        prediction['pct_of_frame'] = prediction['area']/(prediction['img_width'] * prediction['img_height'])\n",
    "        return prediction\n",
    "\n",
    "    def detect(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = cv2.imread(str(image))\n",
    "        img = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR)\n",
    "        img = cv2.resize(img, self.img_size)\n",
    "        self.fd.setInputSize(self.img_size)\n",
    "        _, faces = self.fd.detect(img)\n",
    "        if faces is None:\n",
    "            return None\n",
    "        else:\n",
    "            predictions = self.parse_predictions(image, faces)\n",
    "            return predictions\n",
    "\n",
    "    def parse_predictions(self,\n",
    "                          image,\n",
    "                          faces):\n",
    "        data = []\n",
    "        for num, face in enumerate(list(faces)):\n",
    "            x1, y1, x2, y2 = list(map(int, face[:4]))\n",
    "            landmarks = list(map(int, face[4:len(face)-1]))\n",
    "            landmarks = np.array_split(landmarks, len(landmarks) / 2)\n",
    "            positions = ['left_eye', 'right_eye', 'nose', 'right_mouth', 'left_mouth']\n",
    "            landmarks = {positions[num]: x.tolist() for num, x in enumerate(landmarks)}\n",
    "            confidence = face[-1]\n",
    "            datum = {'x1': x1,\n",
    "                     'y1': y1,\n",
    "                     'x2': x2,\n",
    "                     'y2': y2,\n",
    "                     'face_num': num,\n",
    "                     'landmarks': landmarks,\n",
    "                     'confidence': confidence,\n",
    "                     'model': 'yunet'}\n",
    "            d = self.scale_coords(image, datum)\n",
    "            data.append(d)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "def show_image(image):\n",
    "    _, ret = cv2.imencode('.jpg', image)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FaceDetectorYunet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_1.jpg?raw=true')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_2.jpg?raw=true')\n",
    "img = io.imread('./data/img_2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/636px-NASA_Astronaut_Group_18.jpg\"\n",
    "file_name = \"data/img_2.jpg\"\n",
    "\n",
    "# img = cv2.imread(file_name, 0)\n",
    "img = io.imread(file_name)\n",
    "# img = io.imread('https://github.com/astaileyyoung/CineFace/blob/main/research/notebooks/images/img_2.jpg?raw=true')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fd = FaceDetectorYunet()\n",
    "faces = fd.detect(img)\n",
    "if faces:\n",
    "    fd.draw_faces(img, faces)\n",
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : https://medium.com/@yongsun.yoon/nba-face-recognition-system-345034ffed8c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiap/miniconda3/envs/cv/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import insightface\n",
    "from insightface.app.common import Face\n",
    "from insightface.model_zoo import model_zoo\n",
    "import cv2\n",
    "\n",
    "\n",
    "det_model_path = 'buffalo_s/det_500m.onnx'\n",
    "rec_model_path = 'buffalo_s/w600k_mbf.onnx'\n",
    "\n",
    "det_model = model_zoo.get_model(f'./model/{det_model_path}')\n",
    "# rec_model = model_zoo.get_model(f'./model/{rec_model_path}')\n",
    "\n",
    "det_model.prepare(ctx_id=0, input_size=(640, 640), det_thres=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = [\"data/636px-NASA_Astronaut_Group_18.jpg\", \"data/955px-NASA_Astronaut_Group_18.jpg\",\"data/1432px-NASA_Astronaut_Group_18.jpg\", \"data/foreign-workers-5.jpg\"]\n",
    "\n",
    "img = cv2.imread(file_name[1])\n",
    "\n",
    "bboxes, kpss = det_model.detect(img, max_num=0, metric='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(image,\n",
    "               faces,\n",
    "               draw_landmarks=False,\n",
    "               show_confidence=False):\n",
    "    for face in faces:\n",
    "        color = (0, 0, 255)\n",
    "        thickness = 2\n",
    "        cv2.rectangle(image, (int(face[0]), int(face[1])), (int(face[2]), int(face[3])), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        if draw_landmarks:\n",
    "            landmarks = face['landmarks']\n",
    "            for landmark in landmarks:\n",
    "                radius = 5\n",
    "                thickness = -1\n",
    "                cv2.circle(image, landmark, radius, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        if show_confidence:\n",
    "            confidence = face[4]\n",
    "            confidence = \"{:.2f}\".format(confidence)\n",
    "            position = (int(face[0]), int(face[1] - 10))\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            scale = 0.5\n",
    "            thickness = 2\n",
    "            cv2.putText(image, confidence, position, font, scale, color, thickness, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.putText(img=img,'Test',(100,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = draw_faces(img,bboxes, show_confidence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91072"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(bboxes)\n",
    "# len(kpss)\n",
    "# kpss[0]\n",
    "bbox = bboxes[0, :4]\n",
    "\n",
    "len(bbox)\n",
    "det_score = bboxes[0, 4]\n",
    "\n",
    "det_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201.9659 , 116.19924],\n",
       "       [231.1289 , 118.66086],\n",
       "       [217.08386, 133.66927],\n",
       "       [202.01231, 147.81348],\n",
       "       [227.38632, 149.73907]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpss[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 37,  49,  61],\n",
       "        [ 40,  52,  64],\n",
       "        [ 41,  53,  65],\n",
       "        ...,\n",
       "        [ 21,  30,  33],\n",
       "        [ 21,  30,  33],\n",
       "        [ 21,  30,  33]],\n",
       "\n",
       "       [[ 40,  52,  64],\n",
       "        [ 42,  54,  66],\n",
       "        [ 40,  52,  64],\n",
       "        ...,\n",
       "        [ 25,  34,  37],\n",
       "        [ 26,  35,  38],\n",
       "        [ 26,  35,  38]],\n",
       "\n",
       "       [[ 42,  54,  66],\n",
       "        [ 42,  54,  66],\n",
       "        [ 40,  52,  64],\n",
       "        ...,\n",
       "        [ 28,  37,  40],\n",
       "        [ 28,  37,  40],\n",
       "        [ 27,  36,  39]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 93, 101, 100],\n",
       "        [ 83,  91,  90],\n",
       "        [ 83,  91,  90],\n",
       "        ...,\n",
       "        [ 75,  87,  89],\n",
       "        [ 79,  88,  91],\n",
       "        [ 72,  81,  84]],\n",
       "\n",
       "       [[ 86,  94,  93],\n",
       "        [ 83,  91,  90],\n",
       "        [ 80,  88,  87],\n",
       "        ...,\n",
       "        [ 79,  89,  89],\n",
       "        [ 82,  90,  90],\n",
       "        [ 79,  87,  87]],\n",
       "\n",
       "       [[ 77,  85,  84],\n",
       "        [ 86,  94,  93],\n",
       "        [ 80,  88,  87],\n",
       "        ...,\n",
       "        [ 82,  92,  92],\n",
       "        [ 87,  95,  95],\n",
       "        [ 90,  98,  98]]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# face = bboxes[0]\n",
    "color = (0, 0, 255)\n",
    "# thickness = 2\n",
    "# cv2.rectangle(img, (int(face[0]), int(face[1])), (int(face[2]), int(face[3])), color, thickness, cv2.LINE_AA)\n",
    "\n",
    "cv2.circle(img=img, center=(201,116), radius=3, color=color, thickness=2)\n",
    "cv2.circle(img=img, center=(231,118), radius=2, color=(0, 255, 0), thickness=2)\n",
    "cv2.circle(img=img, center=(217, 134), radius=2, color=(0, 0, 255), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "def show_image(image):\n",
    "    _, ret = cv2.imencode('.jpg', image)\n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([181.54738 ,  88.133606, 245.36903 , 173.82637 ,   0.91072 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerecog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
